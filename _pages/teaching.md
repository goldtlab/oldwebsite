---
permalink: /teaching.html
title: "Teaching"
excerpt: "Teaching"
author_profile: true
---

<p><img src="images/teaching.jpg" alt="Teaching in the garden" title="Teaching in the garden"
width="360" style="float:right; margin:10px" /> 

I am teaching two courses in the academic year 2020/2021 within the <a
href="https://datascience.sissa.it/">SISSA Data Science
PhD</a>


<div style="font-size:130%; font-weight:bold">Introduction to neural networks
</div>
<div style="font-size:115%; font-weight:bold">Spring 2021</div>
<p>The goal of this course is to introduce various approaches to learning with
neural networks. We discuss supervised learning and generative modelling,
feed-forward networks and recurrent architectures, and theory and practice.</p>

<div style="font-size:130%; font-weight:bold">Current topics in the theory of
neural networks</div>
<div style="font-size:115%; font-weight:bold">Summer 2021</div>
<p>This class will give an overview over several areas of current research
interest in the theory of neural networks. Our focus will be on modern
approaches to understand the interplay of data structure, learning algorithm and
architecture in the context of machine learning.</p>

<div style="font-size:130%; font-weight:bold">An introduction to random matrix
theory</div>
<div style="font-size:115%; font-weight:bold">Autumn 2021, joint w/ <a
href="https://datascience.sissa.it/person/28/jean-barbier">J.&nbsp;Barbier (ICTP)</a></div>
<p>The goal of this participatory class is to learn random matrix theory
together. We begin by following the recent book by Bouchaud and Potters. Later,
there will be time to present recent publications depending on our research
interests. This is an introductory class; no previous knowledge of random
matrices is required!</p>
